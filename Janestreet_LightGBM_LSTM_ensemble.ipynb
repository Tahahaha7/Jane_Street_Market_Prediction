{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_CdL6XCcV9a"
   },
   "source": [
    "# $\\text{Jane Street Market Prediction}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN5hdEHxckI9"
   },
   "source": [
    "## $\\text{Getting the data}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Oscar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500) #arbitrary large number, I wanna see all columns\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "#utilities\n",
    "import os\n",
    "from collections import Counter\n",
    "import joblib\n",
    "\n",
    "\n",
    "#MOdels and evalutation\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.7 s, sys: 5.26 s, total: 59 s\n",
      "Wall time: 59.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "working_dir = \"/Users/oscarengelbrektson/Documents/Minerva/Spring 2021 - San Francisco/Quantitative Trading/Jane Street Competition/data/\"\n",
    "\n",
    "train_data = pd.read_csv(working_dir + \"train.csv\")\n",
    "test_data_sample = pd.read_csv(working_dir + \"example_test.csv\")\n",
    "feature_data = pd.read_csv(working_dir + \"features.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Taha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SAUcxFqv2oQ",
    "outputId": "03478b11-b83a-4fe8-ecc0-e58c3f38826a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# getting access to Google Drive to retrieve data\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QvyfvMLwUKX",
    "outputId": "e785c605-f6b5-4ce0-b4e0-4d4d45e0e84c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Kaggle\n"
     ]
    }
   ],
   "source": [
    "# changing the working directory\n",
    "#%cd /content/gdrive/My Drive/Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lckIE5XFwZ0m"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "!kaggle competitions download -c jane-street-market-prediction\n",
    "!unzip \\*.zip  && rm *.zip''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83lSp6EWUet9",
    "outputId": "ec978ba9-fc6a-48e2-e8fc-6c594f17d0bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = pd.read_csv('C:/Users/Taha/Desktop/Spring 2021/JaneStreet/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y181SDMKUrRv",
    "outputId": "48548331-57e3-40ff-b9c1-4b2b9fbd8b26"
   },
   "outputs": [],
   "source": [
    "# difference columns between train and test set\n",
    "#set(train_data.columns) - set(test_sample.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-DO3WhVd0Gf"
   },
   "source": [
    "## $\\text{LightGMB}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjyX3n4DJdf2"
   },
   "source": [
    "### $\\text{Data Processing}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jqR4YUD0Jh6o"
   },
   "outputs": [],
   "source": [
    "#Get outcome variable by transforming resp > 0\n",
    "train_data[\"action\"] = train_data[\"resp\"].apply(lambda x: int(x>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZylOrxiKUaJ",
    "outputId": "c10d91a2-8694-4ec7-f023-7c3f979de8f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 100, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train-validation-test split : 300-100-100\n",
    "train_set = train_data[train_data.date < 300]\n",
    "validation_set = train_data[(train_data.date >= 300) & (train_data.date < 400)]\n",
    "test_set = train_data[train_data.date >= 400]\n",
    "\n",
    "train_set.date.nunique(), validation_set.date.nunique(), test_set.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OD89plgmOinY"
   },
   "outputs": [],
   "source": [
    "predictors = list(set(train_data.columns) - {'resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'action', 'ts_id'})\n",
    "outcome = ['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_set[predictors],  validation_set[predictors], train_set[outcome], validation_set[outcome]\n",
    "X_test, y_test = test_set[predictors], test_set[outcome]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = joblib.load('final_lgbm_model.pkl')\n",
    "lstm = joblib.load('final_lgbm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5Y2tUL00sKAB"
   },
   "outputs": [],
   "source": [
    "y_pred_lgbm = lgbm.predict_proba(X_validation)\n",
    "y_pred_lstm = lstm.predict_proba(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store in Dataframe\n",
    "validation_set[\"lgbm_predicted_prob\"] = y_pred_lgbm[:, 1]\n",
    "validation_set[\"lstm_predicted_prob\"] = y_pred_lstm[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing how the utility changes as a function of the weight assigned to each models predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_score_last(date, weight, resp, action):\n",
    "    '''\n",
    "    Takes four 1-d arrays of equal size:\n",
    "    Date: int\n",
    "    weight: float >= 0\n",
    "    resp: float\n",
    "    action: binary\n",
    "    \n",
    "    and returns jane street utility score, u\n",
    "    '''\n",
    "    count_i = date.nunique() # Get number of days\n",
    "    P_i = np.bincount(date, weight * resp * action) # Compute P_i\n",
    "    t = np.sum(P_i) / np.sqrt(np.sum(P_i ** 2)) * np.sqrt(250 / count_i) # Compute t\n",
    "    u = np.clip(t, 0, 6) * np.sum(P_i) # Combine to get utility score\n",
    "    return u\n",
    "\n",
    "def get_utility_from_df(df, lgbm_weight=0.5):\n",
    "    '''\n",
    "    Takes a dataframe and a decision threshold, \n",
    "    computes the total utility given the decision threshold for converting predicted probabilities to actions\n",
    "    '''\n",
    "    weighted_predictions = (lgbm_weight*df.lgbm_predicted_prob + (1-lgbm_weight)*df.lstm_predicted_prob)\n",
    "    #Transform predictions to actions by Round to 1 or 0\n",
    "    return utility_score_last(df.date, df.weight, df.resp, int(np.round(weighted_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_weights =  np.linspace(0, 1, 200)\n",
    "utility_by_weight = [get_utility_from_df(validation_set, lgbm_weight) for lgbm_weight in lgbm_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgbm_weights = lgbm_weights[utility_by_weight.index(max(utility_by_weight))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(lgbm_weights, utility_by_weight, label=\"Best utility: %s\"%np.round(max(utility_by_threshold), 3))\n",
    "plt.axvline(best_lgbm_weights, \n",
    "            color=\"red\", linestyle=\"--\",label=\"Best lgbm weight: %s\"%np.round(best_threshold, 3))\n",
    "plt.ylabel(\"Utility\")\n",
    "plt.xlabel(\"Weight assigned to LGBM\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(validation_set.lgbm_predicted_prob, validation_set.resp, label=\"r-squared: {}\".format(np.corrcoef(validation_set.lgbm_predicted_prob,\n",
    "                                                                                             validation_set.resp)[0,1]))\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"resp\")\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(validation_set.lgbm_predicted_prob, validation_set.resp, label=\"r-squared: {}\".format(np.corrcoef(validation_set.lgbm_predicted_prob,\n",
    "                                                                                             validation_set.weight)[0,1]))\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"resp\")\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train best model on entire train + validation dataset before running on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_set = pd.concat([train_set, validation_set], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lgbm_model = lgb.LGBMClassifier(max_depth=int(round(best_params[\"max_depth\"])),\n",
    "                                            learning_rate = best_params[\"learning_rate\"],\n",
    "                                            num_leaves = int(round(best_params[\"num_leaves\"])),\n",
    "                                            min_data_in_leaf = int(round(best_params[\"min_data_in_leaf\"])),\n",
    "                                            max_bin=int(round(best_params[\"max_bin\"])),\n",
    "                                            objective = 'binary', \n",
    "                                            boosting= 'gbdt',\n",
    "                                            nthread=10,\n",
    "                                            seed = 42,\n",
    "                                            verbose = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lgbm_model.fit(ttrain_and_validation_setrain_data[predictors],\n",
    "                     train_and_validation_set[outcome].values.reshape(len(train_and_validation_set),), \n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model as pickle file to avoid having to retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# save model\n",
    "joblib.dump(final_lgbm_model, 'final_lgbm_model1.pkl')\n",
    "# load model\n",
    "gbm_pickle = joblib.load('final_lgbm_model1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='gbdt', learning_rate=0.06157343657751557, max_bin=164,\n",
       "               max_depth=6, min_data_in_leaf=10, nthread=10, num_leaves=191,\n",
       "               objective='binary', seed=42, verbose=-1)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute test set utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_preds = final_lgbm_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[\"lgbm_predicted_prob\"] = y_preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_utility_from_df(test_set, best_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abandoned approach using TimeSeriesSplit:\n",
    "Abandoned because was not computationally feasible, would shortcircuit my computers RAM when we tried to use it for hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280617 280613\n",
      "561230 280613\n",
      "841843 280613\n",
      "1122456 280613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#Number of trades in each split, with TimeSeriesSplit\n",
    "X_train, y_train = train_set[predictors], train_set[outcome]\n",
    "ts = TimeSeriesSplit(n_splits=4)\n",
    "for i in ts.split(X_train, y_train):\n",
    "    print(len(i[0]), len(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 44, Test: 53\n",
      "Train: 96, Test: 75\n",
      "Train: 170, Test: 68\n",
      "Train: 237, Test: 64\n"
     ]
    }
   ],
   "source": [
    "#Number of dates in each split, with TimeSeriesSplit\n",
    "\n",
    "ts = TimeSeriesSplit(n_splits=4)\n",
    "for fold_index, holdout_index in ts.split(X_train, y_train):     \n",
    "    X_fold, X_holdout = X_train.iloc[fold_index,:].date.nunique(), X_train.iloc[holdout_index,:].date.nunique()\n",
    "    print('Train: {}, Test: {}'.format(X_fold, X_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "n_folds = 4\n",
    "folds = TimeSeriesSplit(n_splits=n_folds)\n",
    "\n",
    "splits = folds.split(train_set[predictors], train_set[outcome])\n",
    "\n",
    "y_preds = np.zeros(validation_set.shape[0])\n",
    "y_oof = np.zeros(train_set.shape[0])\n",
    "mean_score = []\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = predictors\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "\n",
    "    print('Fold:', fold_n+1)\n",
    "    \n",
    "    X_train, X_valid = train_set[predictors].iloc[train_index], train_set[predictors].iloc[valid_index]\n",
    "    y_train, y_valid = train_set[outcome].iloc[train_index], train_set[outcome].iloc[valid_index]\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, label=y_train)\n",
    "    d_valid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    model = lgb.train(params, d_train, 2500, valid_sets = [d_train, d_valid], early_stopping_rounds = 50, verbose_eval=100)\n",
    "    \n",
    "    feature_importances[f'fold_{fold_n + 1}'] = model.feature_importance()\n",
    "\n",
    "    y_pred_valid = np.round(model.predict(X_valid, num_iteration=model.best_iteration))\n",
    "\n",
    "    y_oof[valid_index] = y_pred_valid\n",
    "    \n",
    "    val_score = accuracy_score(y_pred_valid, y_valid)\n",
    "\n",
    "    print(f'val AUC score is {val_score}')\n",
    "\n",
    "    mean_score.append(val_score)\n",
    "\n",
    "    y_preds += model.predict(validation_set[predictors], num_iteration=model.best_iteration) / n_folds\n",
    "\n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "    gc.collect()\n",
    "\n",
    "print('AUC score over folds is', np.mean(mean_score))\n",
    "\n",
    "#test['demand'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for lightGBM. Objective is minimizing logloss\n",
    "params = {'learning_rate': 0.01,\n",
    "          'boosting': 'gbdt',\n",
    "          'objective': 'binary',\n",
    "          'num_leaves': 200,\n",
    "          'min_data_in_leaf': 10,\n",
    "          'max_bin': 200,\n",
    "          'max_depth': 6,\n",
    "          'seed': 2018,\n",
    "          'nthread': 10}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Janestreet LightGBM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
